# 词向量-fastText
FastText是facebook开源的一款集word2vec、文本分类等一体的机器学习训练工具，是NLP里，一个非常高效的，基于词向量化的，用于文本分类的模型。首先介绍一下字符级别的n-gram。
## 1 字符级别的n-gram
word2vec把语料库中的每个单词当成原子，它会为每个单词生成一个向量，这忽略了单词内部的形态特征，如“apple”与“apples”，两个单词都有较多的公共字符，即它们的内部形态类似，但是在传统的word2vec中，这种单词内部形态信息因为它们被转换成不同的id丢失了。

为了克服这个问题，fastText使用了字符级别的n-grams来表示一个单词，对于“apple”，假设n的取值为3，则它的trigram有："<ap","app","ppl","ple","le>"，其中小于号表示前缀，大于号表示后缀，可以使用这5个trigram的向量叠加来表示“apple”的词向量。

优点： 对于低频词生成的词向量效果会更好，因为它们的n-gram可以和其他词共享；对于训练词库之外的单词，仍然可以构建它们的词向量，可以叠加它们的字符级别n-gram向量。
## 2 模型架构
fastText模型架构和word2vec的CBOW模型架构非常相似，下面通过一个图来展示fastText模型的架构：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/15-1.png)
</div> 

从这个图可以看出来，fastText模型包括输入层、隐含层、输出层共三层。其中输入的是词向量，输出的是label，隐含层是对多个词向量的叠加平均。
## 3 与CBOW模型对比
CBOW是（Continuous Bag-Of-Words Model）的缩写，译为连续字袋模型，大家有兴趣的可以在下面了解一下，下面对fastText模型和CBOW模型进行一个对比：
1. CBOW的输入是目标单词的上下文，fastText的输入是多个单词及其n-gram特征，这些单词用来表示单个文档；
2. CBOW的输入单词被one-hot编码过，fastText的输入特征时被embedding过；
3. CBOW的输出是目标词汇，fastText的输出是文档对应的类标。
## 4 核心思想
将整篇文档的词及n-gram向量叠加平均得到文档向量，然后使用文档向量做softmax多分类。

小技巧：字符级n-gram特征的引入以及分层softmax分类。
