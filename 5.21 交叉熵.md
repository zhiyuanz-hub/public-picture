# 交叉熵
## 1 交叉熵定义
在信息论中，交叉熵是表示两个概率分布p、q，其中p表示真实分布，q表示非真实分布，在相同的一组事件中，其中，用非真实分布q来表示某个事件发生所需要的平均比特数。从这个定义中，我们很难理解交叉熵的定义。下面举个例子来描述一下：

假设现在有一个样本集中两个概率分布p、q，其中p为真实分布，q为非真实分布。假如，按照真实分布p来衡量识别一个样本所需要的编码长度的期望为：
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-1.jpg)
</div> 
但是，如果采用错误的分布q来表示来自真实分布p的平均编码长度，则应该是：
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-2.jpg)
</div> 
此时就将H(p,q)称之为交叉熵。交叉熵的计算方式如下：
+ 对于离散变量采用以下的方式计算：
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-3.jpg)
</div> 
+ 对于连续变量采用以下的方式计算：
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-4.jpg)
</div> 
实际上，交叉熵是衡量两个概率分布p、q之间的相似性。这可以子啊特征工程中，用来衡量变量的重要性。

## 2 交叉熵定义
（1）在特征工程中，可以用来衡量两个随机变量之间的相似度;
（2）语言模型中（NLP），由于真实的分布p是未知的，在语言模型中，模型是通过训练集得到的，交叉熵就是衡量这个模型在测试集上的正确率。其计算方式如下:
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-5.png)
</div>
其中，N是表示的测试集的大小，q(x)表示的是事件x在训练集中的概率（在nlp中就是关键词在训练
语料中的概率）。

（3）在逻辑回归中的应用。由于交叉熵是衡量两个分布之间的相似度，在逻辑回归中，首先数据集真实的分布是p，通过逻辑回归模型预测出来的结果对应的分布是q，此时交叉熵在这里就是衡量预测结果q与真实结果p之间的差异程度，称之为交叉熵损失函数。具体可以这样说：

假设，对应两分类的逻辑回归模型logistic regression来说，他的结果有两个0或者1，在给定预
测向量x，通过logistics regression回归函数g(z)=1/(1+e-z),则真实结果y=1,对应预测结果
y'=g(wx)；真实结果y=0，对应预测结果y'=1-g(wx);以上就是通过g(wx)和1-g(wx)来描述原数据
集0-1分布。根据交叉熵的定义可知：
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-6.png)
</div>
上式是针对测试集一个样本得到的交叉熵。若测试集有N个样本，对应的交叉熵损失函数表示方式如下：
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-7.png)
</div>
最后来介绍机器学习中交叉熵的应用。

## 3 机器学习中交叉熵的应用
1. 为什么要用交叉熵做loss函数？

在线性回归问题中，常常使用MSE（Mean Squared Error）作为loss函数，比如：
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-8.png)
</div>
2. 交叉熵在单分类问题中的使用

这里的单类别是指，每一张图像样本只能有一个类别，比如只能是狗或只能是猫。

交叉熵在单分类问题上基本是标配的方法
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-9.png)
</div>
上式为一张样本的loss计算方法。刚才那个式子中n代表着n种类别。

举例说明,比如有一个样本对应的标签和预测值为
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-10.png)
</div>
那么
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-11.png)
</div>
对应一个batch的loss就是
<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/10-12.png)
</div>
m为当前batch的样本数。



