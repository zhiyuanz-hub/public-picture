# 图像分割
图像分割（image segmentation）技术是计算机视觉领域的个重要的研究方向，是图像语义理解的重要一环。图像分割是指将图像分成若干具有相似性质的区域的过程，从数学角度来看，图像分割是将图像划分成互不相交的区域的过程。近些年来随着深度学习技术的逐步深入，图像分割技术有了突飞猛进的发展，该技术相关的场景物体分割、人体前背景分割、人脸人体Parsing、三维重建等技术已经在无人驾驶、增强现实、安防监控等行业都得到广泛的应用。

图像分割技术从算法演进历程上，大体可划分为基于图论的方法、基于像素聚类的方法和基于深度语义的方法这三大类，在不同的时期涌现出了一批经典的分割算法。
## 1 基于图论的方法
此类方法基于图论的方法利用图论领域的理论和方法，将图像映射为带权无向图，把像素视作节点，将图像分割问题看作是图的顶点划分问题，利用最小剪切准则得到图像的最佳分割。

基于图论的代表有NormalizedCut，GraphCut和GrabCut等方法。
### 1.1 NormalizedCut
想要理解Normalized Cut 需要先理解什么是分割(CUT)与最小化分割（MIN-CUT)，以一个图做例子，把这个图看成一个整体G，现在需要把它分成两个部分。显然中间的红色虚线切割的边就是最小化分割。

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/12-1.png)
</div>

最小化分割解决了把权重图G分成两部分的任务，但是问题来了，来看另一个图，想要的结果是中间实线表示的分割，但是最小化切割却切掉了最边缘的角。这中情况很容易理解，因为最小化切割就是让CUT(A,B)的值最小的情况，而边缘处CUT值确实是最小，因此我们输最小化切割时会有偏差的(bias)。如何去除这种偏差就要引入Normalized Cut算法了。

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/12-2.jpg)
</div>

思路很简单，将Cut normalize一下，除以表现顶点集大小的某种量度，如 vol A = 所有A中顶点
集的度之和，含义是A中所有点到图中所有点的权重的和， 也就是NormalizeCut(A, B) = Cut(A, B) / volA + Cut(A, B) / volB，通过公式可以很清晰的看到NormalizeCut在追求不同子集间点的权重最小值的同时也追求同一子集间点的权重和最大值。
### 1.2 GraphCut
Graph Cuts图是在普通图的基础上多了2个顶点，这2个顶点分别用符号”S”和”T”表示，称为终端顶点。其它所有的顶点都必须和这2个顶点相连形成边集合中的一部分，所以Graph Cuts中有两种顶点，也有两种边，第一种普通顶点对应于图像中的每个像素。每两个邻域顶点的连接就是一条边。这种边也叫n-links。除图像像素外，还有另外两个终端顶点，叫S源点和T汇点。每个普通顶点和这2个终端顶点之间都有连接，组成第二种边,这种边也叫t-links。
### 1.3 GrabCut
Graph Cuts 算法利用了图像的像素灰度信息和区域边界信息，代价函数构建在全局最优的框架下，保证了分割效果。但Graph Cuts 是NP 难问题，且分割结果更倾向于具有相同的类内相似度。
Rother等人提出了基于迭代的图割方法，称为Grab Cut 算法。该算法使用高斯混合模型对目标和
背景建模，利用了图像的RGB色彩信息和边界信息，通过少量的用户交互操作得到非常好的分割效果。
## 2 基于聚类的分割方法
机器学习中的聚类方法也可以用于解决图像分割问题，其一般步骤是:
1. 初始化一个粗糙的聚类
2. 使用迭代的方式将颜色、亮度、纹理等特征相似的像素点聚类到同一超像素，迭代直至收敛，从而得到最终的图像分割结果。

基于像素聚类的代表方法有K-means（K均值），谱聚类等等。
### 2.1 K-means
K-means算法是输入聚类个数k，以及包含 n个数据对象的数据库，输出满足方差最小标准k个聚类
的一种算法。K-means 算法接受输入量 k，然后将N个数据对象划分为 k个聚类以便使得所获得的聚类满足：同一聚类中的对象相似度较高；而不同聚类中的对象相似度较小。

来说一下算法过程：
1. 从N个数据文档（样本）随机选取K个数据文档作为质心（聚类中心）。
2. 对每个数据文档测量其到每个质心的距离，并把它归到最近的质心的类。
3. 重新计算已经得到的各个类的质心。
4. 迭代2~3步直至新的质心与原质心相等或小于指定阈值，算法结束。
### 2.2 谱聚类
谱聚类(Spectral Clustering, SC)是一种基于图论的聚类方法——将带权无向图划分为两个或两个以上的最优子图，使子图内部尽量相似，而子图间距离尽量距离较远，以达到常见的聚类的目的。与K-means算法相比不容易陷入局部最优解，能够对高维度、非常规分布的数据进行聚类。与传统的聚类算法相比具有明显的优势，该算法能在任意形状的样本空间上执行并且收敛于全局最优，这个特点使得它对数据的适应性非常广泛。为了进行聚类，需要利用高斯核计算任意两点间的相似度以此构成相似度矩阵。

谱聚类方法缺点：
+ 谱聚类对参数非常敏感；
+ 时间复杂度和空间复杂度大。

对于k-way谱聚类算法，一般分为以下步骤：
1. 构建相似度矩阵W；
2. 根据相似度矩阵W构建拉普拉斯矩阵L（不同的算法有不同的L矩阵）；
3. 对L进行特征分解，选取特征向量组成特征空间；
4. 在特征空间中利用K均值算法，输出聚类结果；

除了以上2中算法之外呢还有Meanshift和SLIC等别的一些基于聚类的分割方法，在这里就不做过多的解释，大家有兴趣的可以在下面了解一下。

## 3 基于深度语义的方法
聚类方法可以将图像分割成大小均匀、紧凑度合适的超像素块,为后续的处理任务提供基础，但在实际场景的图片中，一些物体的结构比较复杂,内部差异性较大，仅利用像素点的颜色、亮度、纹理等较低层次的内容信息不足以生成好的分割效果，容易产生错误的分割。因此需要更多地结合图像提供的中高层内容信息辅助图像分割，称为图像语义分割。

深度学习技术出现以后，在图像分类任务取得了很大的成功，尤其是其对高级语义信息的model能力很大程度上解决了传统图像分割方法中语义信息缺失的问题。

2013年，LeCun的学生Farabet等人使用有监督的方法训练了一个多尺度的深度卷积分类网络。该网络以某个分类的像素为中心进行多尺度采样，将多尺度的局部图像patch送到CNN分类器中逐一进行分类，最终得到每个像素所属的语义类别。在实际操作中，作者首先对图片进行了超像素聚类，进而对每个超像素进行分类得到最后的分割结果，一定程度上提高了分割的速度。这种做法虽然取得了不错的效果，但是由于逐像素的进行窗口采样得到的始终是局部信息，整体的语义还是不够丰富，于是就有了后面一系列的改进方案。主要的一些比较有代表性的网络呢如FCN（Fully Convolutional Networks for Semantic Segmentation）、DeepLab系列、PSPNet（Pyramid Scene Parsing Network）、U-Net、SegNet，这里主要对FCN进行一下简单的介绍，其余的大家可以在下面具体去细读相关的文章进行了解。Long等人于2014 年提出了FCN方法，这是深度学习在图像分割领域的开山之作，作者针对图像分割问题设计了一种针对任意大小的输入图像，训练端到端的全卷积网络的框架，实现逐像素分类，奠定了使用深度网络解决图像语义分割问题的基础框架。为了克服卷积网络最后输出层缺少空间位置信息这一不足，通过双线性插值上采样和组合中间层输出的特征图，将粗糙(coarse)分割结果转换为密集(dense)分割结果。FCN由于采用的下采样技术会丢失很多细节信息，后续的一系列方法也都做了相应的改进策略。

