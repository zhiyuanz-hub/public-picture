# Tensflow 介绍
TensorFlow是广泛使用的实现机器学习以及其它涉及大量数学运算的算法库之一。TensorFlow由Google开发，是GitHub上最受欢迎的机器学习库之一。Google几乎在所有应用程序中都使用TensorFlow来实现机器学习。 例如，如果您使用到了Google照片或Google语音搜索，那么您就间接使用了TensorFlow模型。它们在大型Google硬件集群上工作，在感知任务方面功能强大。

本次课的主要目的是为TensorFlow提供一个对初学者友好的介绍，假设您已经知道一些python知识。 TensorFlow的核心组件是通过边遍历所有节点的计算图和张量。下面来逐个简单介绍一下。
## 1 张量（Tensor）
来看一张图：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/17-1.png)
</div>

在数学上，张量是N维向量，这意味着张量可以用来表示N维数据集。上面的图有点复杂，难以理解。看看它的简化版本：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/17-2.png)
</div>

上图显示了一些简化的张量。可以看出随着维度的不断增加，数据表示将变得越来越复杂。例如，一个3x3的张量，可以简单地称它为3行和列的矩阵。如果选择另一个形式的张量（1000x3x3），可以称之为一个向量或一组1000个3x3的矩阵。在这里将（1000x3x3）称为张量的形状或尺寸。张量可以是常数也可以是变量。
## 2 计算图（流，flow）
现在理解了Tensor的含义，是时候了解流(Flow)了。流是指一个计算图或简单的一个图，图不能形成环路，通过一个图进行解释，图中的每个节点代表一个操作，如加法、减法等。每个操作都会导致新的张量形成。

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/17-3.png)
</div>

刚才那副图展示了一个简单的计算图，所对应的表达式为：

<div align=center>
    e=(a+b)*(b+1)
</div>

计算图具有以下属性：
1. 叶子顶点或起始顶点始终是张量。意即，操作永远不会发生在图的开头，由此可以推断图中的每个操作都应该接受一个张量并产生一个新的张量。同样，张量不能作为非叶子节点出现，这意味着它们应始终作为输入提供给操作/节点。
2. 计算图总是以层次顺序表达复杂的操作。通过将a+b表示为c，将b+1表示为d，可以分层次组织上述表达式。 因此，可以将e写为：

<div align=center>
    e=(c)*(d)这里 c=a+b且d=b+1。
</div>

3. 以反序遍历图形而形成子表达式，这些子表达式组合起来形成最终表达式。
4. 当正向遍历时，遇到的顶点总是成为下一个顶点的依赖关系，例如没有a和b就无法获得c，同样的，如果不解决c和d则无法获得e。
5. **同级节点的操作彼此独立**，这是计算图的重要属性之一。当按照图中所示的方式构造一个图时，很自然的是，在同一级中的节点，例如c和d，彼此独立，这意味着没有必要在计算d之前计算c。因此它们可以并行执行。
## 3 计算图的并行
上面提到的最后一个属性也就是 **同级节点的操作彼此独立**当然是最重要的属性之一。它清楚地表明，同级的节点是独立的，这意味着在c被计算之前不需空闲，可以在计算c的同时并行计算d。Tensorflow充分利用了这个属性。
## 4 分布执行
Tensorflow允许用户使用并行计算设备更快地执行操作。计算的节点或操作自动调度进行并行计算。这一切都发生在内部，例如在上图中，可以在CPU上调度操作c，在GPU上调度操作d。下面用一个图来展示两种分布式执行的过程：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/17-4.png)
</div>

第一种是单个系统分布式执行，其中单个Tensorflow会话创建单个worker，并且该worker负责在各设备上调度任务。在第二种系统下，有多个worker，他们可以在同一台机器上或不同的机器上，每个worker都在自己的上下文中运行。在上图中，worker进程1运行在独立的机器上，并调度所有可用设备进行计算。
## 5 计算子图
子图是主图的一部分，其本身就是计算图。例如，在之前讲到的一副图中，可以获得许多子图，其中之一来看一下：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/17-5.png)
</div>

这个图是主图的一部分，从之前讲到的属性我们也可以说子图总是表示一个子表达式，因为c是e的子表达式。 子图也满足最后一个属性。同一级别的子图也相互独立，可以并行执行。因此可以在一台设备上调度整个子图。来看一张图：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/17-6.png)
</div>

这个图解释了子图的并行执行。这里有2个矩阵乘法运算，因为它们都处于同一级别，彼此独立，这符合最后一个属性。由于独立性的缘故，节点安排在不同的设备gpu_0和gpu_1上。
## 6 在worker之间交换数据
现在知道Tensorflow将其所有操作分配到由worker管理的不同设备上。更常见的是，worker之间交换张量形式的数据，例如在e=(c)*(d)的图表中，一旦计算出c，就需要将其进一步传递给e，因此Tensor在节点间前向流动。 该流动用一幅图来展示：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/17-7.png)
</div>

此处张量从设备A传递到设备B。这在分布式系统中引起了一些性能延迟。延迟取决于一个重要属性：张量大小。设备B处于空闲模式，直到它接收到设备A的输入。
