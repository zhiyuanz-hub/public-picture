# 深度循环神经网络
之前介绍的循环神经⽹络只有⼀个单向的隐藏层，在深度学习应⽤⾥，我们通常会⽤到含有多个隐藏层的循环神经⽹络，也称作深度循环神经⽹络。来看一张深度循环神经⽹络的架构图，这幅图演⽰了⼀个有L个隐藏层的深度循环神经⽹络，每个隐藏状态不断传递⾄当前层的下⼀时间步和当前时间步的下⼀层。

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/18-1.jpg)
</div>

具体来说，在时间步t⾥，设小批量输⼊Xt∈Rn×d（样本数为n，输⼊个数为d），第ℓ隐藏层
（ℓ=1,...,L）的隐藏状态为Ht(ℓ)∈Rn×h（隐藏单元个数为h），输出层变量为Ot∈Rn×q（输出个数为q），且隐藏层的激活函数为ϕ。第1隐藏层的隐藏状态和之前的计算⼀样：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/18-2.jpg)
</div>

其中权重Wxh(l)∈Rd×h、 Whh(1)∈Rh×h和偏差 bh(1)∈R1×h分别为第1隐藏层的模型参数。
当1<ℓ≤L时，第ℓ隐藏层的隐藏状态的表达式为：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/18-3.jpg)
</div>

其中权重Wxh(ℓ)∈Rh×h、 Whh(ℓ)∈Rh×h和偏差 bh(ℓ)∈R1×h分别为第ℓ隐藏层的模型参数。
最终，输出层的输出只需基于第L隐藏层的隐藏状态：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/18-4.jpg)
</div>

其中权重Whq∈Rh×q和偏差bq∈R1×q为输出层的模型参数。

同多层感知机⼀样，隐藏层个数L和隐藏单元个数h都是超参数。此外，如果将隐藏状态的计算换
成⻔控循环单元或者⻓短期记忆的计算，可以得到深度⻔控循环神经⽹络。

最后总结起来就是：在深度循环神经⽹络中，隐藏状态的信息不断传递⾄当前层的下⼀时间步和当前时间步的下⼀层。