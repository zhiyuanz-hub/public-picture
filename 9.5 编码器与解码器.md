# 编码器与解码器
在⾃然语⾔处理的很多应⽤中，输⼊和输出都可以是不定⻓序列。以机器翻译为例，输⼊可以是⼀段不定⻓的英语⽂本序列，输出可以是⼀段不定⻓的法语⽂本序列，例如

英语输入：“They”、“are”、“watching”、“.”

法语输出：“Ils”、“regardent”、“.”

当输⼊和输出都是不定⻓序列时，可以使⽤编码器—解码器（encoder-decoder）。这两个模型本质上都⽤到了两个循环神经⽹络，分别叫做编码器和解码器。编码器⽤来分析输⼊序列，解码器⽤来⽣成输出序列。

下图描述了使⽤编码器—解码器将上述英语句⼦翻译成法语句⼦的⼀种⽅法。在训练数据集中，可以在每个句⼦后附上特殊符号“<eos>”（end of sequence）以表⽰序列的终⽌。编码器每个时间步的输⼊依次为英语句⼦中的单词、标点和特殊符号“<eos>”。图中使⽤了编码器在最终时间步的隐藏状态作为输⼊句⼦的表征或编码信息。解码器在各个时间步中使⽤输⼊句⼦的编码信息和上个时间步的输出以及隐藏状态作为输⼊。希望解码器在各个时间步能正确依次输出翻译后的法语单词、标点和特殊符号“<eos>”。需要注意的是，解码器在最初时间步的输⼊⽤到了⼀个表⽰序列开始的特殊符号“<bos>”（beginning of sequence）。

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/23-1.jpg)
</div> 

接下来，分别介绍编码器和解码器的定义。

## 1 编码器

编码器的作⽤是把⼀个不定⻓的输⼊序列变换成⼀个定⻓的背景变量c，并在该背景变量中编码
输⼊序列信息。常⽤的编码器是循环神经⽹络。

让我们考虑批量⼤小为1的时序数据样本。假设输⼊序列是x1,...,xT，例如xi是输⼊句⼦中的第i个词。在时间步t，循环神经⽹络将输⼊xt的特征向量xt和上个时间步的隐藏状态ht−1变换为当前时间步的隐藏状态ht。可以⽤函数f表达循环神经⽹络隐藏层的变换：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/23-2.png)
</div> 

接下来，编码器通过⾃定义函数q将各个时间步的隐藏状态变换为背景变量

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/23-3.png)
</div> 

例如，当选择 ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/23-4.png) 时，背景变量是输⼊序列最终时间步的隐藏状态hT。

以上描述的编码器是⼀个单向的循环神经⽹络，每个时间步的隐藏状态只取决于该时间步及之前
的输⼊⼦序列。我们也可以使⽤双向循环神经⽹络构造编码器。在这种情况下，编码器每个时间
步的隐藏状态同时取决于该时间步之前和之后的⼦序列（包括当前时间步的输⼊），并编码了整
个序列的信息。

## 2 解码器

刚刚已经介绍，编码器输出的背景变量c编码了整个输⼊序列x1,...,xT的信息。给定训练样本中的输出序列y1,y2,...,yT′，对每个时间步t′（符号与输⼊序列或编码器的时间步t有区别），解码器
输出yt′的条件概率将基于之前的输出序列y1,..,yt′−1和背景变量c，即P (yt′|y1,...,yt′−1,c)。

为此，可以使⽤另⼀个循环神经⽹络作为解码器。在输出序列的时间步t′，解码器将上⼀时间步的输出yt′−1以及背景变量c作为输⼊，并将它们与上⼀时间步的隐藏状态st′−1变换为当前时间步的隐藏状态st′。因此，可以⽤函数g表达解码器隐藏层的变换：

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/23-5.png)
</div> 

有了解码器的隐藏状态后，可以使⽤⾃定义的输出层和sofmax运算来计算P(yt′|y1,..,yt′−1,c)，例如，基于当前时间步的解码器隐藏状态st′、上⼀时间步的输出yt′−1以及背景变量c来计算当前时间步输出yt′的概率分布。

## 3 训练模型

根据最⼤似然估计，可以最⼤化输出序列基于输⼊序列的条件概率

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/23-6.jpg)
</div>

并得到该输出序列的损失

<div align=center>
    ![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/23-7.png)
</div>

在模型训练中，所有输出序列损失的均值通常作为需要最小化的损失函数。在本节第一个图所描述的模型预测中，需要将解码器在上⼀个时间步的输出作为当前时间步的输⼊。与此不同，在训练中也可以将标签序列（训练集的真实输出序列）在上⼀个时间步的标签作为解码器在当前时间步的输⼊。这叫作强制教学（teacher forcing）。

最后对这一小节进行一个小结：
+ 编码器-解码器可以输⼊并输出不定⻓的序列。
+ 编码器—解码器使⽤了两个循环神经⽹络。
+ 在编码器—解码器的训练中，可以采⽤强制教学。

