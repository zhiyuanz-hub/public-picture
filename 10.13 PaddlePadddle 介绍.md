# PaddlePadddle 介绍
## 1 PaddlePadddle 简介
+ PaddlePaddle是百度研发的开源开放的深度学习平台，有全面的官方支持的工业级应用模型，涵盖自然语言处理、计算机视觉、推荐引擎等多个领域，并开放多个领先的预训练中文模型。
+ PaddlePaddle同时支持稠密参数和稀疏参数场景的大规模深度学习并行训练，支持千亿规模参数、数百个节点的高效并行训练，也可提供深度学习并行技术的深度学习框 。PaddlePaddle拥有多端部署能力，支持服务器端、移动端等多种异构硬件设备的高速推理，预测性能有显著优势。目前PaddlePaddle已经实现了API的稳定和向后兼容，具有完善的中英双语使用文档： http://paddlepaddle.org/documentation/docs/zh/1.4/user_guides/index_cn.html?from=paddlenav
## 2 PaddlePadddle 整体框架
+ 多机并行架构
+ 多GPU并行架构
+ Sequence序列模型
+ 大规模稀疏训练
## 3 PaddlePadddle安装
1. 安装pip: sudo apt-get install python-pip
2. 升级pip: sudo python get-pip.py、wget https://bootstrap.pypa.io/get-pip.py
3. 安装PaddlePaddle: sudo pip install paddlepaddle

## 4 Fluid 简介
### 4.1 使用Tensor表示数据
Fluid和其他主流框架一样，使用Tensor数据结构来承载数据。

在神经网络中传递的数据都是Tensor, Tensor可以简单理解成一个多维数组，一般而言可以有任意多的维度。不同的Tensor可以具有自己的数据类型和形状，同一Tensor中每个元素的数据类型是一样的，Tensor的形状就是Tensor的维度。

**Fluid中存在三种特殊的 Tensor：**
1. 模型中的可学习参数
2. 输入输出Tensor
3. 常量 Tensor
#### 4.1.1 模型中的可学习参数
模型中的可学习参数（包括网络权重、偏置等）生存期和整个训练任务一样长，会接受优化算法的更新，在Fluid中以Variable的子类Parameter表示。在Fluid中可以通过fluid.layers.create_parameter来创建可学习参数：

w = fluid.layers.create_parameter(name="w",shape=[1],dtype='float32')

一般情况下，您不需要自己来创建网络中的可学习参数，Fluid 为大部分常见的神经网络基本计算模块都提供了封装。以最简单的全连接模型为例，下面的代码片段会直接为全连接层创建连接权值（W）和偏置（ bias ）两个可学习参数，无需显式地调用 Parameter 相关接口来创建。

import paddle.fluid as fluid

y = fluid.layers.fc(input=x, size=128, bias_attr=True)
#### 4.1.2 输入输出Tensor
整个神经网络的输入数据也是一个特殊的Tensor，在这个Tensor中，一些维度的大小在定义模型时无法确定（通常包括：batch size（一次训练所选取的样本数），如果mini-batch（样本子集） 之间数据可变，也会包括图片的宽度和高度等），在定义模型时需要占位。

Fluid 中使用 fluid.layers.data 来接收输入数据， fluid.layers.data 需要提供输入 Tensor 的形状信息，当遇到无法确定的维度时，相应维度指定为None，如下面的代码片段所示：

import paddle.fluid as fluid

//定义x的维度为[3,None]，其中我们只能确定x的第一的维度为3，第二个维度未知，要在程序执行过程中才能确定

x = fluid.layers.data(name="x", shape=[3,None], dtype="int64")

//batch size无需显示指定，框架会自动补充第0维为batch size，并在运行时填充正确数值dtype=“int64”表示有符号64位整数数据类型

a = fluid.layers.data(name="a",shape=[3,4],dtype='int64')

//若图片的宽度和高度在运行时可变，将宽度和高度定义为None。

//shape的三个维度含义分别是：channel、图片的宽度、图片的高度

b = fluid.layers.data(name="image",shape=[3,None,None],dtype="float32")
#### 4.1.3 常量Tensor
Fluid 通过 fluid.layers.fill_constant来实现常量Tensor，用户可以指定Tensor的形状，数据类型和常量值。代码实现如下所示：

import paddle.fluid as fluid

data = fluid.layers.fill_constant(shape=[1], value=0, dtype='int64')
### 4.2 数据传入
Fluid有特定的数据传入方式：需要使用 fluid.layers.data配置数据输入层，并在fluid.Executor或fluid.ParallelExecutor中，使用 executor.run(feed=...)传入训练数据。
### 4.3 使用Operator表示对数据的操作
在Fluid中，所有对数据的操作都由Operator表示，您可以使用内置指令来描述他们的神经网络。为了便于用户使用，在Python端，Fluid中的Operator被一步封装入paddle.fluid.layers，paddle.fluid.nets等模块。这是因为一些常见的对Tensor的操作可能是由更多基础操作构成，为了提高使用的便利性，框架内部对基础Operator进行了一些封装，包括创建Operator依赖可学习参数，可学习参数的初始化细节等，减少用户重复开发的成本。
### 4.4 使用Program描述神经网络模型
Fluid不同于其他大部分深度学习框架，去掉了静态计算图的概念，代之以Program的形式动态描述计算过程。这种动态的计算描述方式，兼具网络结构修改的灵活性和模型搭建的便捷性，在保证性能的同时极大地提高了框架对模型的表达能力。开发者的所有Operator都将写入Program，在Fluid内部将自动转化为一种叫作ProgramDesc的描述语言，Program的定义过程就像在写一段通用程序，有开发经验的用户在使用Fluid时，会很自然的将自己的知识迁移过来。其中，Fluid通过提供顺序、分支和循环三种执行结构的支持，让用户可以通过组合描述任意复杂的模型。
### 4.5 使用Executor执行Program
Fluid的设计思想类似于高级编程语言C++和JAVA等。程序的执行过程被分为编译和执行两个阶段。用户完成对Program的定义后，Executor接受这段Program并转化为C++后端真正可执行的FluidProgram，这一自动完成的过程叫做编译。编译过后需要Executor来执行这段编译好的FluidProgram。





