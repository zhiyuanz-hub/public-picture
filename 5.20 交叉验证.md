# 交叉验证（cross-validation）
## 1 概述
交叉验证，交叉验证用于防止模型过于复杂而引起的过拟合。有时亦称循环估计，是一种统计学上将
数据样本切割成较小子集的实用方法。于是可以先在一个子集上做分析，而其它子集则用来做后续对此分析的确认及验证。一开始的子集被称为训练集。而其它的子集则被称为验证集或测试集。交叉验证是一种评估统计分析、机器学习算法对独立于训练数据的数据集的泛化能力。

## 2 交叉验证一般要尽量满足的条件
1. 训练集的比例要足够多，一般大于一半
2. 训练集和测试集要均匀抽样

## 3 交叉验证的分类
（一）k-folder cross-validation

k个子集，每个子集均做一次测试集，其余的作为训练集。交叉验证重复k次，每次选择一个子集作为测试集，并将k次的平均交叉验证识别正确率作为结果。
优点：所有的样本都被作为了训练集和测试集，每个样本都被验证一次。10-folder通常被使用。

（二）K * 2 folder cross-validation

是k-folder cross-validation的一个变体，对每一个folder，都平均分成两个集合s0,s1，先在集合s0训练用s1测试，然后用s1训练s0测试。
优点：测试和训练集都足够大，每一个个样本都被作为训练集和测试集。一般使用k=10。

（三）least-one-out cross-validation(loocv)

假设dataset中有n个样本，那LOOCV也就是n-CV，意思是每个样本单独作为一次测试集，剩余n-1个样本则做为训练集。

优点：
+ 每一回合中几乎所有的样本皆用于训练model，因此最接近母体样本的分布，估测所得的generalization error比较可靠。
+ 实验过程中没有随机因素会影响实验数据，确保实验过程是可以被复制的。
但LOOCV的缺点则是计算成本高，为需要建立的models数量与总样本数量相同，当总样本数量相当多时，LOOCV在实作上便有困难，除非每次训练model的速度很快，或是可以用平行化计算减少计算所需的时间。

接下来具体介绍这里面常用的十折交叉验证。

（四）十折交叉验证

英文名叫做10-fold cross-validation，用来测试算法准确性。是常用的测试方法。将数据集分成十分，轮流将其中9份作为训练数据，1份作为测试数据，进行试验。每次试验都会得出相应的正确率（或差错率）。10次的结果的正确率（或差错率）的平均值作为对算法精度的估计，一般还需要进行多次10折交叉验证（例如10次10折交叉验证），再求其均值，作为对算法准确性的估计。

之所以选择将数据集分为10份，是因为通过利用大量数据集、使用不同学习技术进行的大量试验，表明10折是获得最好误差估计的恰当选择，而且也有一些理论根据可以证明这一点。但这并非最终诊断，争议仍然存在。而且似乎5折或者20折与10折所得出的结果也相差无几。

## 4 如何交叉验证
下面举个例子具体进行说明：

先描述下几个问题：

如何在一些模型中选择一个最好的模型；避免数据浪费；

举例说明：
1. 多项式回归模型中，![image](https://raw.githubusercontent.com/zhiyuanz-hub/public-picture/master/9-1.png) 。我们知道模型越复杂即m越高，拟合效果越好。但是未必是一个好的分类模型，因为模型过拟合了。那么如何确定m的值呢。
2. locally weighted regression中，τ值得确定。
3. SVM中参数C的确定。

交叉验证就是很好的用于这些问题，这些模型中参数寻优的问题。

如何交叉验证：

这里主要介绍K交叉验证：

(1) 将数据集分成K份（网上有说是将数据集分成测试训练两部分，然后将训练部分再分K份，我觉得这样仍然有大部分数据没用于模型训练造成数据浪费。）

(2) 对于每一个模型（拿多项式回归举例，m=2为一个模型，m=3为一个模型。我们主要就是寻找最好的m）
     
     for j=1,2,...,k 
        将除第j份的所有数据作为训练集用于训练，得到训练参数。
        将训练参数在第j份数据上进行测试，得到测试错误E（j）；

(3) 经过第二步就得到了K个模型，和K个测试错误，将这K个错误求平均，就是该模型所估计的泛化误差。

(4) 估计的泛化误差的最小的模型即为我们最优的模型，（例如发现m=3时平均错误最小）我们取这个模型再对所有数据进行训练，得到一个模型参数即为所求。
这样就避免了数据浪费，所有数据都有用于过训练。
